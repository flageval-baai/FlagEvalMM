tasks:
  files:
    - tasks/blink/blink_val.py
  data_root: /data/BLINK/val/
  debug: false
  try_run: true
  output_dir: outputs/demo_run_5
  num_workers: 8

server:
  local_mode: true
  quiet: false

model:
  model_type: http
  model_name: /share/project/models/vlm/Qwen2.5-VL-7B-Instruct
  url: http://localhost:8000/v1/chat/completions
  api_key: EMPTY
  backend: vllm
  extra_args: "--max-model-len 32768"

infer:
  use_cache: false
  temperature: 0.2
  max_tokens: 4096
  num_infers: 1